# LLM Configuration (Model-Centric Design)
# Define available model pool - which models to run is controlled in database

llm:
  # Available model pool - each model can use different service providers
  models:
    deepseek-chat:
      # Which provider to use for this model: 'official' | 'openrouter'
      provider: 'official'

      # Official DeepSeek API configuration
      official:
        base_url: 'https://api.deepseek.com/v1'
        api_key: 'YOUR_DEEPSEEK_API_KEY'  # Get from https://platform.deepseek.com/
        model_name: 'deepseek-chat'
        timeout: 30
        pricing:
          input: '$0.27/1M tokens'
          output: '$1.10/1M tokens'
          cache: '$0.027/1M tokens (90% discount)'

      # OpenRouter configuration (alternative provider for same model)
      openrouter:
        base_url: 'https://openrouter.ai/api/v1'
        api_key: 'YOUR_OPENROUTER_API_KEY'  # Get from https://openrouter.ai/keys
        model_name: 'deepseek/deepseek-chat'
        timeout: 30
        pricing:
          input: '$0.27/1M tokens'
          output: '$1.10/1M tokens'

    qwen-plus:
      provider: 'official'

      official:
        base_url: 'https://dashscope-intl.aliyuncs.com/compatible-mode/v1'
        api_key: 'YOUR_QWEN_API_KEY'  # Get from https://help.aliyun.com/zh/dashscope/
        model_name: 'qwen-plus'
        timeout: 30
        pricing:
          input_output: 'Â¥0.0008/1K tokens'

      openrouter:
        base_url: 'https://openrouter.ai/api/v1'
        api_key: 'YOUR_OPENROUTER_API_KEY'
        model_name: 'qwen/qwen-2.5-72b-instruct'
        timeout: 30
        pricing:
          input: '$0.54/1M tokens'
          output: '$2.24/1M tokens'

    # Example: Additional model accessible only via OpenRouter
    claude-3-5-sonnet:
      provider: 'openrouter'

      openrouter:
        base_url: 'https://openrouter.ai/api/v1'
        api_key: 'YOUR_OPENROUTER_API_KEY'
        model_name: 'anthropic/claude-3.5-sonnet'
        timeout: 30

  # Common LLM settings
  max_tokens: 4096
  temperature: 0.7

# Trading Configuration
trading:
  interval_minutes: 3  # AI decision interval
  coins: ['BTC', 'ETH', 'SOL', 'BNB', 'DOGE', 'XRP']

# HyperLiquid Configuration
hyperliquid:
  testnet: true  # Use testnet for development
  mainnet_url: 'https://api.hyperliquid.xyz'
  testnet_url: 'https://api.hyperliquid-testnet.xyz'

# Database Configuration
database:
  host: localhost
  port: 5432
  database: trading_bot
  user: ${DB_USER}
  password: ${DB_PASSWORD}
  pool_size: 10
  max_overflow: 20

# Which LLM agents to run? Managed in database (trading_agents table)
# Example CLI commands:
#
# Create an agent:
#   python -m trading_bot.cli agent create \
#     --name "DeepSeek Agent" \
#     --model deepseek-chat \
#     --account 0x1234... \
#     --api-key ${HYPERLIQUID_KEY} \
#     --balance 10000.0
#
# List agents:
#   python -m trading_bot.cli agent list
#
# Pause an agent:
#   python -m trading_bot.cli agent pause <agent-id>
#
# For testing with single agent: just create one agent in database
