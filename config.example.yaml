# LLM Configuration (Model-Centric Design)
# Define available model pool - which models to run is controlled in database

llm:
  # Available model pool - each model can use different service providers
  models:
    deepseek-chat:
      # Which provider to use for this model: 'official' | 'openrouter'
      provider: 'official'

      # Official DeepSeek API configuration
      official:
        base_url: 'https://api.deepseek.com/v1'
        api_key: 'YOUR_DEEPSEEK_API_KEY'  # Get from https://platform.deepseek.com/
        model_name: 'deepseek-chat'
        timeout: 30
        pricing:
          input: '$0.27/1M tokens'
          output: '$1.10/1M tokens'
          cache: '$0.027/1M tokens (90% discount)'

      # OpenRouter configuration (alternative provider for same model)
      openrouter:
        base_url: 'https://openrouter.ai/api/v1'
        api_key: 'YOUR_OPENROUTER_API_KEY'  # Get from https://openrouter.ai/keys
        model_name: 'deepseek/deepseek-chat'
        timeout: 30
        pricing:
          input: '$0.27/1M tokens'
          output: '$1.10/1M tokens'

    qwen-plus:
      provider: 'official'

      official:
        base_url: 'https://dashscope-intl.aliyuncs.com/compatible-mode/v1'
        api_key: 'YOUR_QWEN_API_KEY'  # Get from https://help.aliyun.com/zh/dashscope/
        model_name: 'qwen-plus'
        timeout: 30
        pricing:
          input_output: 'Â¥0.0008/1K tokens'

      openrouter:
        base_url: 'https://openrouter.ai/api/v1'
        api_key: 'YOUR_OPENROUTER_API_KEY'
        model_name: 'qwen/qwen-2.5-72b-instruct'
        timeout: 30
        pricing:
          input: '$0.54/1M tokens'
          output: '$2.24/1M tokens'

    # Example: Additional model accessible only via OpenRouter
    claude-3-5-sonnet:
      provider: 'openrouter'

      openrouter:
        base_url: 'https://openrouter.ai/api/v1'
        api_key: 'YOUR_OPENROUTER_API_KEY'
        model_name: 'anthropic/claude-3.5-sonnet'
        timeout: 30

  # Common LLM settings
  max_tokens: 4096
  temperature: 0.7

# HyperLiquid Configuration
exchange:
  testnet: true  # Use testnet for development
  mainnet_url: 'https://api.hyperliquid.xyz'
  testnet_url: 'https://api.hyperliquid-testnet.xyz'

  # Multiple account support - each agent uses one account
  accounts:
    account_1:
      account_id: '0x1234...'  # Your HyperLiquid account address
      api_key: '${HYPERLIQUID_KEY_1}'
      api_secret: '${HYPERLIQUID_SECRET_1}'

    account_2:
      account_id: '0x5678...'
      api_key: '${HYPERLIQUID_KEY_2}'
      api_secret: '${HYPERLIQUID_SECRET_2}'

    # Add more accounts as needed...

# Trading Configuration
trading:
  interval_minutes: 3  # AI decision interval
  coins: ['BTC', 'ETH', 'SOL', 'BNB', 'DOGE', 'XRP']
  kline_limit_3m: 30
  kline_limit_4h: 24

# Database Configuration
database:
  host: localhost
  port: 5432
  database: trading_bot
  user: ${DB_USER}
  password: ${DB_PASSWORD}
  pool_size: 10
  max_overflow: 20

# Which LLM agents to run? Managed in database (trading_agents table)
# Example CLI commands:
#
# Create an agent:
#   bot agent create \
#     --name "DeepSeek Agent" \
#     --model deepseek-chat \
#     --account account_1 \
#     --balance 10000.0
#
# Create another agent with different model and account:
#   bot agent create \
#     --name "Qwen Agent" \
#     --model qwen-plus \
#     --account account_2 \
#     --balance 10000.0
#
# List agents:
#   bot agent list
#
# Pause an agent:
#   bot agent pause <agent-id>
#
# View agent performance:
#   bot agent stats <agent-id>
#
# Note: Agent references model and account names defined above
# API keys are never stored in database - they stay in config.yaml
